{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TuringBench](https://alan-turing-institute.github.io/data-science-benchmarking/) Benchmarking workflow for [ReadabiliPy](https://github.com/alan-turing-institute/ReadabiliPy)\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Software:** [ReadabiliPy](https://github.com/alan-turing-institute/ReadabiliPy) - A simple HTML content extractor in Python. Can be run as a wrapper for Mozilla's Readability.js package or in pure-python mode.\n",
    "\n",
    "**Benchmarks:** Benchmark the speed of core package functions at extracting information from an input HTML with [pytest](https://pypi.org/project/pytest-benchmark/)\n",
    "\n",
    "This benchmarking notebook follows the TuringBench workflow outlined at [https://alan-turing-institute.github.io/data-science-benchmarking/](https://alan-turing-institute.github.io/data-science-benchmarking/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating benchmarks\n",
    "----\n",
    "\n",
    "To get started with the TuringBench workflow, I created a branch of the ReadabiliPy repository (called ```benchmarking```) and added benchmarks to the pre-existing pytest tests, which was easy with the [pytest-benchmark](https://pypi.org/project/pytest-benchmark/) package, making sure to also add this package in the ```requirements-dev.txt``` used by ReadabiliPy.\n",
    "\n",
    "I followed the pytest-benchmark instructions, setting up benchmarks for some of the ReadabiliPy package functions, which get run alongside existing tests with the command ```pytest```. We can also run the benchmarks only (ignoring other tests) with ```pytest --benchmark-only```.\n",
    "\n",
    "Once happy with the benchmarks I wanted, I committed these changes and pushed to them to the remote ```benchmarking``` branch on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Docker image for Benchmarking ReadabiliPy\n",
    "----\n",
    "\n",
    "The Dockerfile below installs the requirements for ReadabiliPy and pulls the latest commit of the ```benchmarking``` branch from GitHub, then runs the benchmarks with pytest.\n",
    "\n",
    "*Note: After the benchmarking branch of the project is merged, the ```git clone``` command will need to be edited to the master branch (see the Post development version of the Dockerfile at the end of this notebook)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3\n",
    "\n",
    "# Install requirements\n",
    "RUN apt-get update\n",
    "RUN apt-get -y install curl\n",
    "RUN curl -sL https://deb.nodesource.com/setup_11.x | bash -\n",
    "RUN apt install nodejs\n",
    "RUN npm install\n",
    "RUN pip install --upgrade pip\n",
    "RUN apt-get install -y git\n",
    "\n",
    "# Clone ReadabiliPy and install python packages\n",
    "RUN git clone -b benchmarking --single-branch https://github.com/alan-turing-institute/ReadabiliPy\n",
    "WORKDIR \"/ReadabiliPy\"\n",
    "RUN git pull\n",
    "RUN pip install -r requirements-dev.txt\n",
    "\n",
    "# Run the benchmarks with Pytest\n",
    "CMD pytest --benchmark-only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  52.74kB\r",
      "\r\n",
      "Step 1/13 : FROM python:3\n",
      " ---> ac069ebfe1e1\n",
      "Step 2/13 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 5a84d23aa7b5\n",
      "Step 3/13 : RUN apt-get -y install curl\n",
      " ---> Using cache\n",
      " ---> fa727cce5ef4\n",
      "Step 4/13 : RUN curl -sL https://deb.nodesource.com/setup_11.x | bash -\n",
      " ---> Using cache\n",
      " ---> 6072028d5b8f\n",
      "Step 5/13 : RUN apt install nodejs\n",
      " ---> Using cache\n",
      " ---> c493d1b01b96\n",
      "Step 6/13 : RUN npm install\n",
      " ---> Using cache\n",
      " ---> c952a91935a8\n",
      "Step 7/13 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 92e402750d57\n",
      "Step 8/13 : RUN apt-get install -y git\n",
      " ---> Using cache\n",
      " ---> 1b10afe3306c\n",
      "Step 9/13 : RUN git clone -b benchmarking --single-branch https://github.com/alan-turing-institute/ReadabiliPy\n",
      " ---> Using cache\n",
      " ---> cf99a8e9e4c9\n",
      "Step 10/13 : WORKDIR \"/ReadabiliPy\"\n",
      " ---> Using cache\n",
      " ---> 6560e34a1b59\n",
      "Step 11/13 : RUN git pull\n",
      " ---> Using cache\n",
      " ---> 2ec7fdcee516\n",
      "Step 12/13 : RUN pip install -r requirements-dev.txt\n",
      " ---> Using cache\n",
      " ---> 9576b4a99312\n",
      "Step 13/13 : CMD pytest --benchmark-only\n",
      " ---> Using cache\n",
      " ---> ec0ce7e0828a\n",
      "Successfully built ec0ce7e0828a\n",
      "Successfully tagged edwardchalstrey/readabilipy_benchmark:latest\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker build -t edwardchalstrey/readabilipy_benchmark:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the containerised benchmarks\n",
    "----\n",
    "\n",
    "After pushing the container to remote repository/registry (e.g. to Docker Hub with ```docker push edwardchalstrey/readabilipy_benchmark:latest```), we can then ```docker run``` the benchmarks for ReadabiliPy on coputing platforms of our choosing and compare benchmarks across platforms and when new features are added.\n",
    "\n",
    "### Results\n",
    "\n",
    "I have benchmarked three of the html parsing features of ReadabiliPy on an example html file; see the tests in [ReadabiliPy](https://github.com/alan-turing-institute/ReadabiliPy/tree/master) repo within ```tests/test_benchmarking.py```.\n",
    "\n",
    "Benchmarks run on these dates, are for the following [ReadabiliPy](https://github.com/alan-turing-institute/ReadabiliPy/tree/master) commits:\n",
    "1. 2019-05-02 => [9ba2fdb7...](https://github.com/alan-turing-institute/ReadabiliPy/commit/9ba2fdb71b3b014f3252a29672ff41159203e45c)\n",
    "2. 2019-05-14 => [d3b3c365...](https://github.com/alan-turing-institute/ReadabiliPy/commit/d3b3c365984aa26ce0a8f0fda6b3fd75b9e837a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Benchmarks; (mean time ms)</td><td>Date      </td><td>Container on MacBook</td><td>MacBook  </td></tr>\n",
       "<tr><td>Title parse               </td><td>2019-05-02</td><td>40.2649             </td><td>55.5296  </td></tr>\n",
       "<tr><td>Title parse               </td><td>2019-05-14</td><td>39.7405             </td><td>54.8936  </td></tr>\n",
       "<tr><td>Date parse                </td><td>2019-05-02</td><td>46.4389             </td><td>69.5056  </td></tr>\n",
       "<tr><td>Date parse                </td><td>2019-05-14</td><td>32.8276             </td><td>44.4991  </td></tr>\n",
       "<tr><td>Full parse                </td><td>2019-05-02</td><td>3065.2467           </td><td>2140.0745</td></tr>\n",
       "<tr><td>Full parse                </td><td>2019-05-14</td><td>2642.1735           </td><td>1942.1609</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "table = [[\"Benchmarks; (mean time ms)\", \"Date\", \"Container on MacBook\", \"MacBook\"],\n",
    "         [\"Title parse\", \"2019-05-02\", 40.2649, 55.5296],\n",
    "         [\"Title parse\", \"2019-05-14\", 39.7405, 54.8936],\n",
    "         [\"Date parse\", \"2019-05-02\", 46.4389, 69.5056],\n",
    "         [\"Date parse\", \"2019-05-14\", 32.8276, 44.4991],\n",
    "         [\"Full parse\", \"2019-05-02\", 3065.2467, 2140.0745],\n",
    "         [\"Full parse\", \"2019-05-14\", 2642.1735, 1942.1609],\n",
    "        ]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated build\n",
    "====\n",
    "\n",
    "The ```latest``` tag for ```edwardchalstrey/readabilipy_benchmark``` [on Docker Hub](https://cloud.docker.com/repository/docker/edwardchalstrey/readabilipy_benchmark) has been set to build whenever the master branch of the ReadabiliPy GitHub repo has a new commit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post development Dockerfile\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3\n",
    "\n",
    "# Install requirements\n",
    "RUN apt-get update\n",
    "RUN apt-get -y install curl\n",
    "RUN curl -sL https://deb.nodesource.com/setup_11.x | bash -\n",
    "RUN apt install nodejs\n",
    "RUN npm install\n",
    "RUN pip install --upgrade pip\n",
    "RUN apt-get install -y git\n",
    "\n",
    "# Clone ReadabiliPy and install python packages\n",
    "RUN git clone https://github.com/alan-turing-institute/ReadabiliPy\n",
    "WORKDIR \"/ReadabiliPy\"\n",
    "RUN git pull\n",
    "RUN pip install -r requirements-dev.txt\n",
    "\n",
    "# Run the benchmarks with Pytest\n",
    "CMD pytest --benchmark-only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
